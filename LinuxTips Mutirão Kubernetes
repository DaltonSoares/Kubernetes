------------------------------------------------------------------------------------------------------------------------------------------------------

DIA 1
INTRODUÇÃO

O que é um container?
Isolamento de recursos. 
O container não tem um Kernel próprio, ele usa o kernel do host hospedeiro. 

Orquestrador de containers:
Não podemos ter apenas um container em ambiente produtivo, é necessário ter mais réplicas desses containers, daí vem a necessidade do orquestrador para conseguir colocar um serviço
apontando para o POD, conseguir colocar ordem na casa organizando todas as réplicas dos containers.

90% dos orquestradores de containers hoje em dia refere-se ao Kubernetes, é o mais popular, tem também o Nômade da hashcorp.

Kubernetes foi iniciado no Google e lá pra 2014/15 o Google resolveu deixar público para a comunidade também contribuir. O Google doou o projeto para a Linux Foundation.
CNCF ( cloud native ... ) Vale a pena acreditar no Kubernetes pois quem está "por trás" dele é a Linux Foundation, orgão sério, o Docker Swarm por exemplo foi deixado de lado.

É importante também conhecer Linux pois a maioria dos cluster Kubernetes rodam em Linux.

Qual a função do Kubernetes?
Colocar o DNS nos PODs / serviços, regra de como os serviços vão se comunicar, tudo está centralizado no K8S.

Cada Nó (node) tem o seu papel, parte vai ser para se a saúde do cluster está tudo OK. São os CONTROL-PLANE. Ele é como se fosse o cérebro do cluster, api-server, etc, 
tudo isso normalmente está no control-plane. 
Geralmente não se executa containers nos nodes control-plane. Os containers são normalmente executado nos workers. Control-plane fica só para a saúde do cluster.

Tem os K8S gerenciados, Oracle, Azure, AWS, etc, "essa parte do control plane eu não quero cuidar, eu quero cuidar dos workers", quem cuida disso é a própria cloud e eu 
me preocupo só com os workers.
Para criar esse cluster gerenciado pode ser via terraform, na console da cloud. 

K8S Vanilla - Diretamente do site do Kubernetes, normalmente será utilizado uma ferramenta chamada kubeadm. Que é criar o cluster na mão.

OKD - Open Kubernetes Distribution, é uma distribuição do Kubernetes, como se fosse uma distribuição Linux.

Kubernetes temos também o desenvolvimento local, o minikube (em cima de máquinas virtuais) e o kind (funciona em cima do Docker).
Primeira dica, instalem o kind ou minikube.

------------------------------------------------------------------------------------------------------------------------------------------------------
https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqa1BzOWJWMDJDZDRuSXAxUWNrNVZmbExOenRuQXxBQ3Jtc0ttOEl6eFprNWoxS0FQVVhKc0FmZEVqVTVFZTFWQ3ZkM18xR0lJLVAwMlhTTTVvdjd4MThhNm5NSGxtLXJRWkZRY2VXSXlnUktYZ3dLUkp5a0Rkc3BBeTZlX2RncTFEemJObm1BSWZNVklRZnQ3b2h1Yw&q=https%3A%2F%2Fplay.instruqt.com%2Flinuxtips%2Finvite%2Fzrm7jsac3ybz
https://play.instruqt.com/linuxtips/invite/zrm7jsac3ybz/tracks/mutiro-kubernetes---primeiro-dia


https://github.com/badtuxx/CertifiedContainersExpert/tree/main/DescomplicandoKubernetes/day-1#kind

Não esqueça que o kubectl é o seu principal aliado nessa jornada! Mantenha-o sempre por perto!
kubectl é o responsável por administrar o cluster via linha de comando.
https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqbUl3VUZyZXpmM0h6RERaVWVQU01uaWMwN1g5QXxBQ3Jtc0tsVXp6X1VHMk9xVnEzR1FWYUNlU2Q3cFdMOF93T3dqa3hvbzVkTnJZTWhrM3RDa1hUVXNLbUxuNWNqaktsbnNVRGJNbGJmX29RRW1ocnRvTWZILVg3bnB5UFhCNHN0YUFmYmsyWkVnbEpaMlNoakRvTQ&q=https%3A%2F%2Fgithub.com%2Fbadtuxx%2FCertifiedContainersExpert%2Ftree%2Fmain%2FDescomplicandoKubernetes%2Fday-1%23instala%25C3%25A7%25C3%25A3o-do-kubectl-no-gnulinux
https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqa0V2eDd3REN3NmM5dWJDYk01dGg2Uk8wUUhPUXxBQ3Jtc0trcTZPNFBjS1oyV1hKdm5HcEFpelhiTXB6VDQ4SFJLMUVxT0s5VG9qMHpYckUzSDZSMzR6bXpmOUxyTFlBU1ZWc3UxMlo2b1dpZ2Y1RVkxdkNPRC00Q3ZzX2s5YzhnU2JWS2ljblJuV0xaZTVjN1Z4bw&q=https%3A%2F%2Fgithub.com%2Fbadtuxx%2FCertifiedContainersExpert%2Ftree%2Fmain%2FDescomplicandoKubernetes%2Fday-1%23instala%25C3%25A7%25C3%25A3o-do-kubectl-no-gnulinux

O kubectl fala com a API para saber o que vai ser feito.

curl -fsSL https://get.docker.com | bash
curl -fsSL https://get.docker.com | bash
kubectl cluster-info

No kubernetes a menor unidade é o POD, o kubernetes não vai tratar containers, vai tratar PODs.
Namespace é uma forma de agrupar, kube-system é o namespace onde está o control-plane.

root@linuxtips-server:~# kubectl get pods -A -o wide
kubectl run nginx --image nginx

pod/nginx created

kubectl exec -ti nginx -- bash

------------------------------------------------------------------------------------------------------------------------------------------------------

DIA 2
A menor unidade no Kubernetes é o POD, e dentro dele pode ter 1 ou mais containers. Esses dois ou mais containers que estiverem rodando dentro do mesmo pod vai
ser compartilhado, toda infra, etc.

kubectl run nginx --image nginx - Dessa maneira ele faz o download dessa imagem lá no dockerhub, como não passamos a versão da imagem foi feito o download da última versão.
kubectl describe pod nginx - Describe traz mais informações sobre o POD.

Um service serve para expor um deployment, pod, statefulset para fora do cluster.

clusterIp - Todo mundo que está dentro do cluster consegue acessar.
nodePort - Vai pegar uma porta alta e aí quem vai acessar esse serviço precisa colocar ip:porta
loadBalancer - Se está rodando dentro de alguma cloud, quando utilizo um serviço do tipo LoadBalancer, o K8S fala com a Cloud e vai criar esse LoadBalancer na Cloud
e as pessoas conseguem acessar.

kubectl run nginx --image nginx --port  80
kubectl expose pod - dessa maneira criou um service, mas eu não escolhi o tipo.
kubectl get services
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
nginx        ClusterIP   10.43.27.227   <none>        80/TCP    21s


kubectl expose pod nginx --type NodePort
kubectl expose pod nginx --type LoadBalancer

Quando você quer acessar um servico nós podemos usar o port foward.

kubectl port-forward svc/nginx 8080:80 - dar uma lida sobre kubectl port-foward para entender um pouco mais.

DEPLOYMENT
Quando estou utilizando um deployment vou poder ter uma ou mais réplicas do meu componente, garantindo alta disponibilidade.
Caso um dos PODs caia, o kubernetes vai tirar esse POD do jogo e subir um novo.

SERVIÇO e embaixo dele terão as réplicas dos PODs.

kubectl create deployment giropops --image nginx --port 80 --replicas 3
deployment.apps/giropops created

kubectl scale deployment giropops --replicas 5
deployment.apps/giropops scaled


------------------------------------------------------------------------------------------------------------------------------------------------------

DIA 3
labels são muito importantes, para utilizar em conjunto com os services.

apiVersion: v1
kind: Pod
metadata:
  name: giropops
  namespace: default
  labels:
    app: nginx
spec:
  containers:
  - name: girus
    image: nginx
    ports:
    - containerPort: 80
    resources:
      limits:
        cpu: 0.5
        memory: 128Mi
      requests:
        cpu: 0.25
        memory: 64Mi

kubectl apply -f meu-pod.yaml

resources:
  limits: MÁXIMO
  requests: É COMO ELE VAI SUBIR.
  
  Posso instalar o stress para fazer os testes, isso utilizando dentro do exec no pod.
  k exec -ti giropops -- bash
  
  k create deployment strigus --image nginx --replicas 3 dry-run=client -o yaml > mey-deployment.yaml
  da maneira acima vai criar um arquivo yaml pra mim com a definição.
  
  kubectl top
  
  https://github.com/kelseyhightower/kubernetes-the-hard-way
















