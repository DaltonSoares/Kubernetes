------------------------------------------------------------------------------------------------------------------------------------------------------

DIA 1
INTRODU√á√ÉO

O que √© um container?
Isolamento de recursos. 
O container n√£o tem um Kernel pr√≥prio, ele usa o kernel do host hospedeiro. 

Orquestrador de containers:
N√£o podemos ter apenas um container em ambiente produtivo, √© necess√°rio ter mais r√©plicas desses containers, da√≠ vem a necessidade do orquestrador para conseguir colocar um servi√ßo
apontando para o POD, conseguir colocar ordem na casa organizando todas as r√©plicas dos containers.

90% dos orquestradores de containers hoje em dia refere-se ao Kubernetes, √© o mais popular, tem tamb√©m o N√¥made da hashcorp.

Kubernetes foi iniciado no Google e l√° pra 2014/15 o Google resolveu deixar p√∫blico para a comunidade tamb√©m contribuir. O Google doou o projeto para a Linux Foundation.
CNCF ( cloud native ... ) Vale a pena acreditar no Kubernetes pois quem est√° "por tr√°s" dele √© a Linux Foundation, org√£o s√©rio, o Docker Swarm por exemplo foi deixado de lado.

√â importante tamb√©m conhecer Linux pois a maioria dos cluster Kubernetes rodam em Linux.

Qual a fun√ß√£o do Kubernetes?
Colocar o DNS nos PODs / servi√ßos, regra de como os servi√ßos v√£o se comunicar, tudo est√° centralizado no K8S.

Cada N√≥ (node) tem o seu papel, parte vai ser para se a sa√∫de do cluster est√° tudo OK. S√£o os CONTROL-PLANE. Ele √© como se fosse o c√©rebro do cluster, api-server, etc, 
tudo isso normalmente est√° no control-plane. 
Geralmente n√£o se executa containers nos nodes control-plane. Os containers s√£o normalmente executado nos workers. Control-plane fica s√≥ para a sa√∫de do cluster.

Tem os K8S gerenciados, Oracle, Azure, AWS, etc, "essa parte do control plane eu n√£o quero cuidar, eu quero cuidar dos workers", quem cuida disso √© a pr√≥pria cloud e eu 
me preocupo s√≥ com os workers.
Para criar esse cluster gerenciado pode ser via terraform, na console da cloud. 

K8S Vanilla - Diretamente do site do Kubernetes, normalmente ser√° utilizado uma ferramenta chamada kubeadm. Que √© criar o cluster na m√£o.

OKD - Open Kubernetes Distribution, √© uma distribui√ß√£o do Kubernetes, como se fosse uma distribui√ß√£o Linux.

Kubernetes temos tamb√©m o desenvolvimento local, o minikube (em cima de m√°quinas virtuais) e o kind (funciona em cima do Docker).
Primeira dica, instalem o kind ou minikube.

------------------------------------------------------------------------------------------------------------------------------------------------------
https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqa1BzOWJWMDJDZDRuSXAxUWNrNVZmbExOenRuQXxBQ3Jtc0ttOEl6eFprNWoxS0FQVVhKc0FmZEVqVTVFZTFWQ3ZkM18xR0lJLVAwMlhTTTVvdjd4MThhNm5NSGxtLXJRWkZRY2VXSXlnUktYZ3dLUkp5a0Rkc3BBeTZlX2RncTFEemJObm1BSWZNVklRZnQ3b2h1Yw&q=https%3A%2F%2Fplay.instruqt.com%2Flinuxtips%2Finvite%2Fzrm7jsac3ybz
https://play.instruqt.com/linuxtips/invite/zrm7jsac3ybz/tracks/mutiro-kubernetes---primeiro-dia


https://github.com/badtuxx/CertifiedContainersExpert/tree/main/DescomplicandoKubernetes/day-1#kind

N√£o esque√ßa que o kubectl √© o seu principal aliado nessa jornada! Mantenha-o sempre por perto!
kubectl √© o respons√°vel por administrar o cluster via linha de comando.
https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqbUl3VUZyZXpmM0h6RERaVWVQU01uaWMwN1g5QXxBQ3Jtc0tsVXp6X1VHMk9xVnEzR1FWYUNlU2Q3cFdMOF93T3dqa3hvbzVkTnJZTWhrM3RDa1hUVXNLbUxuNWNqaktsbnNVRGJNbGJmX29RRW1ocnRvTWZILVg3bnB5UFhCNHN0YUFmYmsyWkVnbEpaMlNoakRvTQ&q=https%3A%2F%2Fgithub.com%2Fbadtuxx%2FCertifiedContainersExpert%2Ftree%2Fmain%2FDescomplicandoKubernetes%2Fday-1%23instala%25C3%25A7%25C3%25A3o-do-kubectl-no-gnulinux
https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqa0V2eDd3REN3NmM5dWJDYk01dGg2Uk8wUUhPUXxBQ3Jtc0trcTZPNFBjS1oyV1hKdm5HcEFpelhiTXB6VDQ4SFJLMUVxT0s5VG9qMHpYckUzSDZSMzR6bXpmOUxyTFlBU1ZWc3UxMlo2b1dpZ2Y1RVkxdkNPRC00Q3ZzX2s5YzhnU2JWS2ljblJuV0xaZTVjN1Z4bw&q=https%3A%2F%2Fgithub.com%2Fbadtuxx%2FCertifiedContainersExpert%2Ftree%2Fmain%2FDescomplicandoKubernetes%2Fday-1%23instala%25C3%25A7%25C3%25A3o-do-kubectl-no-gnulinux

O kubectl fala com a API para saber o que vai ser feito.

curl -fsSL https://get.docker.com | bash
curl -fsSL https://get.docker.com | bash
kubectl cluster-info

No kubernetes a menor unidade √© o POD, o kubernetes n√£o vai tratar containers, vai tratar PODs.
Namespace √© uma forma de agrupar, kube-system √© o namespace onde est√° o control-plane.

root@linuxtips-server:~# kubectl get pods -A -o wide
kubectl run nginx --image nginx

pod/nginx created

kubectl exec -ti nginx -- bash

------------------------------------------------------------------------------------------------------------------------------------------------------

DIA 2
A menor unidade no Kubernetes √© o POD, e dentro dele pode ter 1 ou mais containers. Esses dois ou mais containers que estiverem rodando dentro do mesmo pod vai
ser compartilhado, toda infra, etc.

kubectl run nginx --image nginx - Dessa maneira ele faz o download dessa imagem l√° no dockerhub, como n√£o passamos a vers√£o da imagem foi feito o download da √∫ltima vers√£o.
kubectl describe pod nginx - Describe traz mais informa√ß√µes sobre o POD.

Um service serve para expor um deployment, pod, statefulset para fora do cluster.

clusterIp - Todo mundo que est√° dentro do cluster consegue acessar.
nodePort - Vai pegar uma porta alta e a√≠ quem vai acessar esse servi√ßo precisa colocar ip:porta
loadBalancer - Se est√° rodando dentro de alguma cloud, quando utilizo um servi√ßo do tipo LoadBalancer, o K8S fala com a Cloud e vai criar esse LoadBalancer na Cloud
e as pessoas conseguem acessar.

kubectl run nginx --image nginx --port  80
kubectl expose pod - dessa maneira criou um service, mas eu n√£o escolhi o tipo.
kubectl get services
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
nginx        ClusterIP   10.43.27.227   <none>        80/TCP    21s


kubectl expose pod nginx --type NodePort
kubectl expose pod nginx --type LoadBalancer

Quando voc√™ quer acessar um servico n√≥s podemos usar o port foward.

kubectl port-forward svc/nginx 8080:80 - dar uma lida sobre kubectl port-foward para entender um pouco mais.

DEPLOYMENT
Quando estou utilizando um deployment vou poder ter uma ou mais r√©plicas do meu componente, garantindo alta disponibilidade.
Caso um dos PODs caia, o kubernetes vai tirar esse POD do jogo e subir um novo.

SERVI√áO e embaixo dele ter√£o as r√©plicas dos PODs.

kubectl create deployment giropops --image nginx --port 80 --replicas 3
deployment.apps/giropops created

kubectl scale deployment giropops --replicas 5
deployment.apps/giropops scaled


------------------------------------------------------------------------------------------------------------------------------------------------------

DIA 3
labels s√£o muito importantes, para utilizar em conjunto com os services.

apiVersion: v1
kind: Pod
metadata:
  name: giropops
  namespace: default
  labels:
    app: nginx
spec:
  containers:
  - name: girus
    image: nginx
    ports:
    - containerPort: 80
    resources:
      limits:
        cpu: 0.5
        memory: 128Mi
      requests:
        cpu: 0.25
        memory: 64Mii

kubectl apply -f meu-pod.yaml

resources:
  limits: M√ÅXIMO
  requests: √â COMO ELE VAI SUBIR.
  
  Posso instalar o stress para fazer os testes, isso utilizando dentro do exec no pod.
  k exec -ti giropops -- bash
  
  k create deployment strigus --image nginx --replicas 3 dry-run=client -o yaml > mey-deployment.yaml
  da maneira acima vai criar um arquivo yaml pra mim com a defini√ß√£o.
  
  kubectl top
  
  https://github.com/kelseyhightower/kubernetes-the-hard-way

------------------------------------------------------------------------------------------------------------------------------------------------------

O nosso objetivo aqui √© fazer a instala√ß√£o do Nginx!

Aten√ß√£o! üì¢
Corrija todos os erros encontrados e realize o deploy do Nginx utilizando o arquivo deployment.yaml.

Tarefas
Utilize o arquivo /root/deployment.yaml para realizar o deploy do nosso Deployment;
Corrija todos os erros;
Configure o limite de utiliza√ß√£o de recursos da seguinte maneira:
Requests:
64Mi de Mem√≥ria;
0.5 de CPU;
Limits:
128 Mi de Mem√≥ria;
0.7 de CPU;
Use a estrat√©gia de atualiza√ß√£o do Deployment que atualiza todos os pods de uma vez;
A vers√£o do Nginx deve ser a 1.16.0.

ERRADO PARA CORRIGIR
apiVersion: app/v1
kind: Deployment
metadata:
  label:
    app: nginx-girus
    opa: sensacional-juvenal
name: nginx-girus
specs:
  replicas: 5
    selector:
      matchLabels:
      app: nginx-girus
  strategies:
    type: recreate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 2
  strategies: {}
  replicas: 2
  template:
    metadata:
    label:
      app: nginx
    specs:
      containers:
      - image: nginx 1.15.0
        name: nginx
        resource: {}
        
FUNCIONOU
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-girus
  labels:
    app: nginx-girus
    opa: sensacional-juvenal
spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx-girus
  template:
    metadata:
      labels:
        app: nginx-girus
    spec:
      containers:
        - name: nginx
          image: nginx 1.16.0
          ports:
          - containerPort: 80
          resources:
            requests:
              cpu: 0.1
              memory: 64Mi
            limits:
              cpu: 0.3
              memory: 128Mi















